2009-05-09T19:08:00.000Z	buzzzz		hello all, how can i defrag a drive that is not mounted?
2009-05-09T19:08:00.000Z	ActionParsnip	buzzzz	is it an ntfs partition?
2009-05-09T19:08:00.000Z	ActionParsnip	buzzzz	you dont defrag drives ;)
2009-05-09T19:16:00.000Z	ActionParsnip	buzzzz	the disk data is mildly fragmented but due to the nature of modern OSes, the disk reading is fragmented too so having a mild amount of fragmentation can improve speed
2009-05-09T19:17:00.000Z	ActionParsnip	buzzzz	it is very rare a single file will be read in one go due to the multiple threads and different file read / writes that happen on a disk
2009-05-09T19:22:00.000Z	ActionParsnip	buzzzz	you can convert ext3 to ext2, defrag, then convert to ext3 but you will gain very little and defragging stresses the drive physically
2009-05-09T19:23:00.000Z	buzzzz	ActionParsnip	ext3 to ext2, would that be a matter of mounting the partition as ext2? I hope so, as it would make life easier. :)
2009-05-09T19:23:00.000Z	ActionParsnip	buzzzz	no, you'd need to remove the journal
2009-05-09T19:24:00.000Z	ActionParsnip	buzzzz	the journal is the thing that prevents the fragmentation
2009-05-09T19:24:00.000Z	buzzzz	ActionParsnip	thanks, i will go down that path, after some serious consideration of whether this is worthwhile on a 2TB partition
2009-05-09T19:24:00.000Z	ActionParsnip	buzzzz	its really not
2009-05-09T19:24:00.000Z	ActionParsnip	buzzzz	but its good to try once just to show how good ext3 is with fragmentation
2009-05-09T19:25:00.000Z	buzzzz	ActionParsnip	I am sorry to come across a bit thick, but really as I understand it, it is impossible to prevent fragmantation alltogether, maybe for general use it is unlikely, i've put about 10tb through a 2gb drive with lots of individual file deletes etc..
2009-05-09T19:26:00.000Z	ActionParsnip	buzzzz	well, you'll see the result when you are done. but if you think about all the processes accessing the disk
2009-05-09T19:26:00.000Z	ActionParsnip	buzzzz	the disk access is fragmented, so 100% contiguous files will slow down the access
2009-05-09T19:27:00.000Z	ActionParsnip	buzzzz	just like daisy wheel printers did not have the letters in alphabetical order, but had the most used ones together
2009-05-09T19:29:00.000Z	buzzzz	ActionParsnip	i would have expected that if i am copying a 70gb file (typically tarball of /home) to a backup location, then the read operation on the 70gb file should perform at its best when contigious
2009-05-09T19:30:00.000Z	ActionParsnip	buzzzz	no, you will never read a 70Gb file in one lump, the OS needs the drive for its other processes too doesnt it, so halfway, it will stop and go and read some other data, then have to come ALL the way back. If some of the data is near the 2nd data it read it will be faster won't it
2009-05-09T19:32:00.000Z	buzzzz	ActionParsnip	sorry I should have mentioned this drive is not the system drive, it is used entirely for storing userdata.
2009-05-09T19:33:00.000Z	ActionParsnip	buzzzz	well if you have multiple files open on that drive, the same still applies
2009-05-09T19:33:00.000Z	buzzzz	ActionParsnip	I see you point though, very valid.
2009-05-09T19:34:00.000Z	buzzzz	ActionParsnip	thanks, I'll going to take your word for it, i think i might be looking into too much detail in an environment I cant control..
2009-05-09T19:35:00.000Z	ActionParsnip	buzzzz	thats because they rwad screens and scripts. they have no real knowledge
